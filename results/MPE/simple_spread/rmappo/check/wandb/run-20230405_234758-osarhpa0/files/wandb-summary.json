{"value_loss": 0.01443905346095562, "_timestamp": 1680752967.6907682, "policy_loss": -0.008330093386117454, "dist_entropy": 0.9787747025489807, "actor_grad_norm": 0.25128841400146484, "critic_grad_norm": 0.08702058345079422, "ratio": 0.9992400407791138, "average_episode_rewards": -141.75280332565308, "agent0/individual_rewards": -1.6604991656615402, "agent1/individual_rewards": -1.6448741656615402, "agent2/individual_rewards": -1.6604991656615402, "_runtime": 89.18479013442993, "_step": 579200}